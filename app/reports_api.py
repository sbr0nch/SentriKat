"""
API endpoints for scheduled reports management.
"""

from flask import Blueprint, request, jsonify, session, send_file, Response
from app.models import ScheduledReport, Organization, User
from app import db, csrf
from datetime import datetime
import logging

logger = logging.getLogger(__name__)

bp = Blueprint('reports_api', __name__)

# Exempt API routes from CSRF (they use JSON and are protected by SameSite cookies)
csrf.exempt(bp)


def login_required(f):
    """Decorator to require login for API endpoints"""
    from functools import wraps

    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401
        return f(*args, **kwargs)
    return decorated_function


def admin_required(f):
    """Decorator to require admin access"""
    from functools import wraps

    @wraps(f)
    def decorated_function(*args, **kwargs):
        if 'user_id' not in session:
            return jsonify({'error': 'Authentication required'}), 401

        user = User.query.get(session['user_id'])
        if not user or user.role not in ['org_admin', 'super_admin']:
            return jsonify({'error': 'Admin access required'}), 403

        return f(*args, **kwargs)
    return decorated_function


def _add_report_integrity(report_data, generated_by_user=None):
    """
    Add integrity and attestation metadata to a compliance report.

    Adds:
    - report_id: Unique identifier for this report instance
    - document_integrity.sha256: Hash of the report data (excluding integrity block)
    - document_integrity.hmac_sha256: HMAC signature using the app's secret key
    - attestation: Legal clause and generation context
    - audit_trail: Who generated it, from which installation, at what time

    This allows recipients to verify the report has not been tampered with
    and provides a chain of custody for regulatory compliance.
    """
    import hashlib
    import hmac
    import uuid
    import json as _json
    from flask import current_app

    # Load branding settings to support white-label in reports
    from app.settings_api import get_setting
    app_name = get_setting('app_name', 'SentriKat')
    report_branding = get_setting('report_branding_enabled', 'true') == 'true'
    generator_name = f"{app_name} Vulnerability Management Platform" if report_branding else 'Vulnerability Management Platform'

    # Generate unique report ID
    report_id = f"SK-RPT-{uuid.uuid4().hex[:16].upper()}"
    report_data['report_id'] = report_id

    # Audit trail
    audit = {
        'generated_at': report_data.get('generated_at', datetime.utcnow().isoformat() + 'Z'),
        'generated_by': generated_by_user.username if generated_by_user else 'system',
        'generator': generator_name,
        'generator_version': None,
        'report_id': report_id,
    }

    # Get app version and installation ID
    try:
        from app.licensing import _get_app_version, get_installation_id
        audit['generator_version'] = _get_app_version()
        audit['installation_id'] = get_installation_id()
    except Exception:
        pass

    report_data['audit_trail'] = audit

    # Attestation clause
    if report_branding:
        attestation_statement = (
            f'This report was automatically generated by {app_name} based on vulnerability '
            'data collected from monitored endpoints and cross-referenced against the CISA '
            'Known Exploited Vulnerabilities catalog and vendor security advisories. '
            'The data reflects the state of the system at the time of generation. '
            'This report has not been independently audited or certified by a third party.'
        )
    else:
        attestation_statement = (
            'This report was automatically generated based on vulnerability '
            'data collected from monitored endpoints and cross-referenced against the CISA '
            'Known Exploited Vulnerabilities catalog and vendor security advisories. '
            'The data reflects the state of the system at the time of generation. '
            'This report has not been independently audited or certified by a third party.'
        )

    report_data['attestation'] = {
        'statement': attestation_statement,
        'data_sources': [
            'CISA Known Exploited Vulnerabilities (KEV) Catalog',
            'National Vulnerability Database (NVD)',
            'Vendor Security Advisories (OSV, Red Hat, MSRC, Debian)',
            'EPSS (Exploit Prediction Scoring System)',
        ],
        'limitations': (
            'This report covers only software inventory collected by deployed agents. '
            'Unmonitored endpoints, network devices, and cloud services are not included. '
            'Vulnerability matching depends on accurate CPE identification.'
        ),
    }

    # Document integrity - hash the report content (excluding the integrity block itself)
    # Create a canonical JSON representation for hashing
    hashable_data = {k: v for k, v in report_data.items() if k != 'document_integrity'}
    canonical = _json.dumps(hashable_data, sort_keys=True, default=str)
    content_hash = hashlib.sha256(canonical.encode('utf-8')).hexdigest()

    # HMAC signature using the app's SECRET_KEY for tamper detection
    secret_key = current_app.config.get('SECRET_KEY', '').encode('utf-8')
    hmac_sig = hmac.new(secret_key, canonical.encode('utf-8'), hashlib.sha256).hexdigest()

    verification_instance = f'the generating {app_name} instance' if report_branding else 'the generating instance'
    report_data['document_integrity'] = {
        'algorithm': 'SHA-256',
        'content_hash': content_hash,
        'hmac_sha256': hmac_sig,
        'verification_note': (
            'To verify this report has not been modified: '
            '1) Remove the document_integrity block from the JSON. '
            '2) Serialize the remaining data with sorted keys. '
            '3) Compare the SHA-256 hash against content_hash. '
            f'The HMAC signature can only be verified by {verification_instance}.'
        ),
    }

    return report_data


@bp.route('/api/reports/scheduled', methods=['GET'])
@login_required
def get_scheduled_reports():
    """Get all scheduled reports for the current organization"""
    org_id = session.get('organization_id')
    if not org_id:
        return jsonify({'error': 'Organization not found'}), 400

    reports = ScheduledReport.query.filter_by(organization_id=org_id).all()
    return jsonify([r.to_dict() for r in reports])


@bp.route('/api/reports/scheduled/<int:report_id>', methods=['GET'])
@login_required
def get_scheduled_report(report_id):
    """Get a specific scheduled report"""
    org_id = session.get('organization_id')
    report = ScheduledReport.query.filter_by(id=report_id, organization_id=org_id).first()

    if not report:
        return jsonify({'error': 'Report not found'}), 404

    return jsonify(report.to_dict())


@bp.route('/api/reports/scheduled', methods=['POST'])
@admin_required
def create_scheduled_report():
    """Create a new scheduled report"""
    org_id = session.get('organization_id')
    if not org_id:
        return jsonify({'error': 'Organization not found'}), 400

    data = request.get_json()

    # Validate required fields
    if not data.get('name'):
        return jsonify({'error': 'Report name is required'}), 400
    if not data.get('recipients') and not data.get('send_to_managers') and not data.get('send_to_admins'):
        return jsonify({'error': 'At least one recipient method is required'}), 400

    # Validate frequency
    frequency = data.get('frequency', 'weekly')
    if frequency not in ScheduledReport.FREQUENCY_CHOICES:
        return jsonify({'error': f'Invalid frequency. Must be one of: {ScheduledReport.FREQUENCY_CHOICES}'}), 400

    # Validate day_of_week for weekly
    if frequency == 'weekly':
        day_of_week = data.get('day_of_week', 0)
        if not isinstance(day_of_week, int) or day_of_week < 0 or day_of_week > 6:
            return jsonify({'error': 'day_of_week must be 0-6 for weekly reports'}), 400
    else:
        day_of_week = None

    # Validate day_of_month for monthly
    if frequency == 'monthly':
        day_of_month = data.get('day_of_month', 1)
        if not isinstance(day_of_month, int) or day_of_month < 1 or day_of_month > 28:
            return jsonify({'error': 'day_of_month must be 1-28 for monthly reports'}), 400
    else:
        day_of_month = None

    # Validate time_of_day
    time_of_day = data.get('time_of_day', '09:00')
    try:
        datetime.strptime(time_of_day, '%H:%M')
    except ValueError:
        return jsonify({'error': 'time_of_day must be in HH:MM format'}), 400

    # Validate report_type
    report_type = data.get('report_type', 'summary')
    if report_type not in ScheduledReport.REPORT_TYPE_CHOICES:
        return jsonify({'error': f'Invalid report_type. Must be one of: {ScheduledReport.REPORT_TYPE_CHOICES}'}), 400

    try:
        report = ScheduledReport(
            organization_id=org_id,
            name=data['name'],
            description=data.get('description'),
            frequency=frequency,
            day_of_week=day_of_week,
            day_of_month=day_of_month,
            time_of_day=time_of_day,
            report_type=report_type,
            include_acknowledged=data.get('include_acknowledged', True),
            include_pending=data.get('include_pending', True),
            include_trends=data.get('include_trends', True),
            priority_filter=data.get('priority_filter'),
            recipients=data.get('recipients', ''),
            send_to_managers=data.get('send_to_managers', False),
            send_to_admins=data.get('send_to_admins', True),
            enabled=data.get('enabled', True),
            created_by=session.get('user_id')
        )

        # Calculate next run time
        report.calculate_next_run()

        db.session.add(report)
        db.session.commit()

        logger.info(f"Created scheduled report '{report.name}' for org {org_id}")

        return jsonify({
            'success': True,
            'message': 'Scheduled report created',
            'report': report.to_dict()
        }), 201

    except Exception as e:
        db.session.rollback()
        logger.exception("Error creating scheduled report")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


@bp.route('/api/reports/scheduled/<int:report_id>', methods=['PUT'])
@admin_required
def update_scheduled_report(report_id):
    """Update a scheduled report"""
    org_id = session.get('organization_id')
    report = ScheduledReport.query.filter_by(id=report_id, organization_id=org_id).first()

    if not report:
        return jsonify({'error': 'Report not found'}), 404

    data = request.get_json()

    try:
        # Update fields
        if 'name' in data:
            report.name = data['name']
        if 'description' in data:
            report.description = data['description']
        if 'frequency' in data:
            if data['frequency'] not in ScheduledReport.FREQUENCY_CHOICES:
                return jsonify({'error': f'Invalid frequency'}), 400
            report.frequency = data['frequency']
        if 'day_of_week' in data:
            report.day_of_week = data['day_of_week']
        if 'day_of_month' in data:
            report.day_of_month = data['day_of_month']
        if 'time_of_day' in data:
            try:
                datetime.strptime(data['time_of_day'], '%H:%M')
                report.time_of_day = data['time_of_day']
            except ValueError:
                return jsonify({'error': 'time_of_day must be in HH:MM format'}), 400
        if 'report_type' in data:
            if data['report_type'] not in ScheduledReport.REPORT_TYPE_CHOICES:
                return jsonify({'error': f'Invalid report_type'}), 400
            report.report_type = data['report_type']
        if 'include_acknowledged' in data:
            report.include_acknowledged = data['include_acknowledged']
        if 'include_pending' in data:
            report.include_pending = data['include_pending']
        if 'include_trends' in data:
            report.include_trends = data['include_trends']
        if 'priority_filter' in data:
            report.priority_filter = data['priority_filter']
        if 'recipients' in data:
            report.recipients = data['recipients']
        if 'send_to_managers' in data:
            report.send_to_managers = data['send_to_managers']
        if 'send_to_admins' in data:
            report.send_to_admins = data['send_to_admins']
        if 'enabled' in data:
            report.enabled = data['enabled']

        # Recalculate next run
        report.calculate_next_run()

        db.session.commit()

        logger.info(f"Updated scheduled report '{report.name}'")

        return jsonify({
            'success': True,
            'message': 'Scheduled report updated',
            'report': report.to_dict()
        })

    except Exception as e:
        db.session.rollback()
        logger.exception("Error updating scheduled report")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


@bp.route('/api/reports/scheduled/<int:report_id>', methods=['DELETE'])
@admin_required
def delete_scheduled_report(report_id):
    """Delete a scheduled report"""
    org_id = session.get('organization_id')
    report = ScheduledReport.query.filter_by(id=report_id, organization_id=org_id).first()

    if not report:
        return jsonify({'error': 'Report not found'}), 404

    try:
        name = report.name
        db.session.delete(report)
        db.session.commit()

        logger.info(f"Deleted scheduled report '{name}'")

        return jsonify({
            'success': True,
            'message': 'Scheduled report deleted'
        })

    except Exception as e:
        db.session.rollback()
        logger.exception("Error deleting scheduled report")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


@bp.route('/api/reports/scheduled/<int:report_id>/toggle', methods=['POST'])
@admin_required
def toggle_scheduled_report(report_id):
    """Toggle enabled/disabled status of a scheduled report"""
    org_id = session.get('organization_id')
    report = ScheduledReport.query.filter_by(id=report_id, organization_id=org_id).first()

    if not report:
        return jsonify({'error': 'Report not found'}), 404

    try:
        report.enabled = not report.enabled
        if report.enabled:
            report.calculate_next_run()
        db.session.commit()

        status = 'enabled' if report.enabled else 'disabled'
        logger.info(f"Scheduled report '{report.name}' {status}")

        return jsonify({
            'success': True,
            'message': f'Scheduled report {status}',
            'enabled': report.enabled,
            'next_run': report.next_run.isoformat() if report.next_run else None
        })

    except Exception as e:
        db.session.rollback()
        logger.exception("Error toggling scheduled report")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


@bp.route('/api/reports/scheduled/<int:report_id>/send-now', methods=['POST'])
@admin_required
def send_report_now(report_id):
    """Manually trigger a scheduled report to send immediately"""
    org_id = session.get('organization_id')
    report = ScheduledReport.query.filter_by(id=report_id, organization_id=org_id).first()

    if not report:
        return jsonify({'error': 'Report not found'}), 404

    try:
        from app.reports import VulnerabilityReportGenerator
        from app.email_alerts import EmailAlertManager

        # Generate the report
        generator = VulnerabilityReportGenerator(organization_id=org_id)

        if report.report_type == 'summary':
            pdf_buffer = generator.generate_monthly_report()
        else:
            # Full report with current date range
            from datetime import datetime, timedelta
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            pdf_buffer = generator.generate_custom_report(
                start_date=start_date,
                end_date=end_date,
                include_acknowledged=report.include_acknowledged,
                include_pending=report.include_pending
            )

        # Get recipients
        recipients = report.get_recipient_emails()
        if not recipients:
            return jsonify({
                'success': False,
                'message': 'No recipients configured for this report'
            }), 400

        # Send email with attachment
        org = Organization.query.get(org_id)
        org_name = org.display_name if org else 'Unknown'

        result = EmailAlertManager.send_scheduled_report(
            recipients=recipients,
            report_name=report.name,
            org_name=org_name,
            pdf_buffer=pdf_buffer
        )

        # Update report status
        report.last_sent = datetime.utcnow()
        report.last_status = 'success' if result.get('success') else 'failed'
        db.session.commit()

        if result.get('success'):
            return jsonify({
                'success': True,
                'message': f'Report sent to {len(recipients)} recipient(s)',
                'recipients': recipients
            })
        else:
            return jsonify({
                'success': False,
                'message': result.get('error', 'Failed to send report')
            }), 500

    except Exception as e:
        logger.exception("Error sending report manually")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


@bp.route('/api/reports/download', methods=['POST'])
@login_required
def download_report():
    """Generate and download a report immediately"""
    from app.reports import VulnerabilityReportGenerator
    from datetime import datetime, timedelta

    org_id = session.get('organization_id')
    data = request.get_json() or {}

    report_type = data.get('report_type', 'monthly')
    include_acknowledged = data.get('include_acknowledged', True)
    include_pending = data.get('include_pending', True)

    try:
        generator = VulnerabilityReportGenerator(organization_id=org_id)

        if report_type == 'monthly':
            year = data.get('year')
            month = data.get('month')
            pdf_buffer = generator.generate_monthly_report(year=year, month=month)
            filename = f"vulnerability_report_{datetime.now().strftime('%Y_%m')}.pdf"

        elif report_type == 'custom':
            start_date = datetime.fromisoformat(data['start_date'])
            end_date = datetime.fromisoformat(data['end_date'])
            pdf_buffer = generator.generate_custom_report(
                start_date=start_date,
                end_date=end_date,
                include_acknowledged=include_acknowledged,
                include_pending=include_pending
            )
            filename = f"vulnerability_report_{start_date.strftime('%Y%m%d')}-{end_date.strftime('%Y%m%d')}.pdf"

        elif report_type == 'selected':
            match_ids = data.get('match_ids', [])
            if not match_ids:
                return jsonify({'error': 'No vulnerabilities selected'}), 400
            pdf_buffer = generator.generate_selected_report(match_ids)
            filename = f"selected_vulnerabilities_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"

        else:
            # Default to last 30 days
            end_date = datetime.now()
            start_date = end_date - timedelta(days=30)
            pdf_buffer = generator.generate_custom_report(
                start_date=start_date,
                end_date=end_date,
                include_acknowledged=include_acknowledged,
                include_pending=include_pending
            )
            filename = f"vulnerability_report_{datetime.now().strftime('%Y%m%d')}.pdf"

        return send_file(
            pdf_buffer,
            mimetype='application/pdf',
            as_attachment=True,
            download_name=filename
        )

    except Exception as e:
        logger.exception("Error generating report")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


# ============================================================================
# CISA BOD 22-01 Compliance Report
# ============================================================================

@bp.route('/api/reports/compliance/bod-22-01', methods=['GET'])
@login_required
def generate_compliance_report():
    """
    Generate CISA BOD 22-01 compliance report.

    CISA Binding Operational Directive 22-01 requires federal agencies to:
    1. Remediate known exploited vulnerabilities (KEV) by their due dates
    2. Report compliance status

    This report shows:
    - Total KEV vulnerabilities applicable to your products
    - Remediation status (acknowledged vs pending)
    - Overdue vulnerabilities
    - Compliance percentage
    - Timeline analysis

    Query Parameters:
        format: 'json' or 'pdf' (default: json)
        organization_id: Filter by organization (admin only)
    """
    from app.licensing import requires_professional, get_license
    from app.models import Vulnerability, VulnerabilityMatch, Product, Organization
    from sqlalchemy import func
    from datetime import date, timedelta
    from io import BytesIO

    # Check professional license
    license_info = get_license()
    if not license_info or not license_info.is_professional():
        return jsonify({
            'error': 'CISA BOD 22-01 Compliance Reports require a Professional license',
            'feature': 'compliance_reports'
        }), 403

    output_format = request.args.get('format', 'json').lower()
    org_id = request.args.get('organization_id', type=int)

    user = User.query.get(session.get('user_id'))
    if not user:
        return jsonify({'error': 'Authentication required'}), 401

    # Determine organization scope
    if user.role == 'super_admin' and org_id:
        org_filter = [org_id]
    elif user.role == 'super_admin':
        org_filter = None  # All organizations
    else:
        org_filter = [m.organization_id for m in user.org_memberships.all()]

    today = date.today()

    # Build query for matches
    from app.models import product_organizations as po_table
    from sqlalchemy import or_, exists, select

    matches_query = db.session.query(
        VulnerabilityMatch,
        Vulnerability,
        Product
    ).join(
        Vulnerability, VulnerabilityMatch.vulnerability_id == Vulnerability.id
    ).join(
        Product, VulnerabilityMatch.product_id == Product.id
    )

    if org_filter:
        # Include products linked via legacy FK or many-to-many org table
        org_link_exists = exists(
            select(po_table.c.product_id).where(
                po_table.c.product_id == Product.id,
                po_table.c.organization_id.in_(org_filter)
            )
        )
        matches_query = matches_query.filter(
            or_(Product.organization_id.in_(org_filter), org_link_exists)
        )

    matches = matches_query.all()

    # Calculate metrics
    total_matches = len(matches)
    acknowledged = sum(1 for m, v, p in matches if m.acknowledged)
    pending = total_matches - acknowledged

    # Overdue analysis
    overdue = []
    due_soon = []  # Due within 7 days
    on_track = []

    for match, vuln, product in matches:
        if match.acknowledged:
            continue

        if vuln.due_date:
            if vuln.due_date < today:
                overdue.append({
                    'cve_id': vuln.cve_id,
                    'product': f"{product.vendor} {product.product_name}",
                    'due_date': vuln.due_date.isoformat(),
                    'days_overdue': (today - vuln.due_date).days,
                    'severity': vuln.severity,
                    'known_ransomware': vuln.known_ransomware
                })
            elif vuln.due_date <= today + timedelta(days=7):
                due_soon.append({
                    'cve_id': vuln.cve_id,
                    'product': f"{product.vendor} {product.product_name}",
                    'due_date': vuln.due_date.isoformat(),
                    'days_remaining': (vuln.due_date - today).days,
                    'severity': vuln.severity
                })
            else:
                on_track.append({
                    'cve_id': vuln.cve_id,
                    'product': f"{product.vendor} {product.product_name}",
                    'due_date': vuln.due_date.isoformat()
                })

    # Severity breakdown for pending
    severity_breakdown = {'CRITICAL': 0, 'HIGH': 0, 'MEDIUM': 0, 'LOW': 0, 'UNKNOWN': 0}
    for match, vuln, product in matches:
        if not match.acknowledged:
            sev = vuln.severity or 'UNKNOWN'
            severity_breakdown[sev] = severity_breakdown.get(sev, 0) + 1

    # Ransomware exposure
    ransomware_exposure = sum(
        1 for m, v, p in matches
        if not m.acknowledged and v.known_ransomware
    )

    # Calculate compliance percentage
    compliance_percent = round((acknowledged / total_matches * 100), 1) if total_matches > 0 else 100.0

    # Build report data
    report = {
        'report_type': 'CISA BOD 22-01 Compliance',
        'generated_at': datetime.utcnow().isoformat() + 'Z',
        'report_period': {
            'as_of_date': today.isoformat()
        },
        'summary': {
            'total_kev_matches': total_matches,
            'remediated': acknowledged,
            'pending_remediation': pending,
            'compliance_percentage': compliance_percent,
            'overdue_count': len(overdue),
            'due_within_7_days': len(due_soon),
            'ransomware_exposure': ransomware_exposure
        },
        'compliance_status': 'COMPLIANT' if len(overdue) == 0 and compliance_percent >= 95 else 'NON-COMPLIANT',
        'severity_breakdown': severity_breakdown,
        'overdue_vulnerabilities': sorted(overdue, key=lambda x: x['days_overdue'], reverse=True)[:20],
        'due_soon': sorted(due_soon, key=lambda x: x['days_remaining'])[:10],
        'recommendations': []
    }

    # Add recommendations
    if len(overdue) > 0:
        report['recommendations'].append(
            f"URGENT: {len(overdue)} vulnerabilities are past their CISA due date. "
            "Immediate remediation required per BOD 22-01."
        )
    if ransomware_exposure > 0:
        report['recommendations'].append(
            f"HIGH RISK: {ransomware_exposure} unpatched vulnerabilities are known to be "
            "used in ransomware campaigns. Prioritize these for immediate remediation."
        )
    if len(due_soon) > 0:
        report['recommendations'].append(
            f"ATTENTION: {len(due_soon)} vulnerabilities have due dates within the next 7 days."
        )
    if severity_breakdown.get('CRITICAL', 0) > 0:
        report['recommendations'].append(
            f"CRITICAL: {severity_breakdown['CRITICAL']} critical severity vulnerabilities "
            "require immediate attention."
        )

    # Add integrity metadata (signatures, hashes, attestation, audit trail)
    _add_report_integrity(report, generated_by_user=user)

    if output_format == 'json':
        return jsonify(report)

    # Generate PDF
    elif output_format == 'pdf':
        try:
            from reportlab.lib import colors
            from reportlab.lib.pagesizes import letter
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch

            buffer = BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=letter)
            styles = getSampleStyleSheet()
            story = []

            # Title
            title_style = ParagraphStyle(
                'Title',
                parent=styles['Heading1'],
                fontSize=18,
                spaceAfter=20
            )
            story.append(Paragraph("CISA BOD 22-01 Compliance Report", title_style))
            story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}", styles['Normal']))
            story.append(Spacer(1, 20))

            # Compliance Status
            status_color = colors.green if report['compliance_status'] == 'COMPLIANT' else colors.red
            status_style = ParagraphStyle(
                'Status',
                parent=styles['Heading2'],
                textColor=status_color
            )
            story.append(Paragraph(f"Status: {report['compliance_status']}", status_style))
            story.append(Paragraph(f"Compliance: {compliance_percent}%", styles['Normal']))
            story.append(Spacer(1, 20))

            # Summary table
            summary_data = [
                ['Metric', 'Value'],
                ['Total KEV Matches', str(total_matches)],
                ['Remediated', str(acknowledged)],
                ['Pending', str(pending)],
                ['Overdue', str(len(overdue))],
                ['Due Within 7 Days', str(len(due_soon))],
                ['Ransomware Exposure', str(ransomware_exposure)]
            ]
            summary_table = Table(summary_data, colWidths=[3*inch, 2*inch])
            summary_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ]))
            story.append(summary_table)
            story.append(Spacer(1, 20))

            # Recommendations
            if report['recommendations']:
                story.append(Paragraph("Recommendations:", styles['Heading2']))
                for rec in report['recommendations']:
                    story.append(Paragraph(f"• {rec}", styles['Normal']))
                story.append(Spacer(1, 20))

            # Overdue vulnerabilities
            if overdue:
                story.append(Paragraph("Overdue Vulnerabilities (Top 10):", styles['Heading2']))
                overdue_data = [['CVE ID', 'Product', 'Days Overdue', 'Severity']]
                for item in overdue[:10]:
                    overdue_data.append([
                        item['cve_id'],
                        item['product'][:30],
                        str(item['days_overdue']),
                        item['severity'] or 'N/A'
                    ])
                overdue_table = Table(overdue_data, colWidths=[1.5*inch, 2.5*inch, 1*inch, 1*inch])
                overdue_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.darkred),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                    ('GRID', (0, 0), (-1, -1), 1, colors.black),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('FONTSIZE', (0, 0), (-1, -1), 8),
                ]))
                story.append(overdue_table)

            # Attestation & Integrity footer
            story.append(Spacer(1, 30))
            footer_style = ParagraphStyle('Footer', parent=styles['Normal'], fontSize=7, textColor=colors.grey)
            story.append(Paragraph(f"Report ID: {report.get('report_id', 'N/A')}", footer_style))
            story.append(Paragraph(f"SHA-256: {report.get('document_integrity', {}).get('content_hash', 'N/A')}", footer_style))
            story.append(Paragraph(report.get('attestation', {}).get('statement', ''), footer_style))

            doc.build(story)
            buffer.seek(0)

            filename = f"bod_22_01_compliance_{today.strftime('%Y%m%d')}.pdf"
            return send_file(
                buffer,
                mimetype='application/pdf',
                as_attachment=True,
                download_name=filename
            )

        except ImportError:
            return jsonify({'error': 'PDF generation requires reportlab library'}), 500
        except Exception as e:
            logger.exception("Error generating compliance PDF")
            return jsonify({'error': 'PDF generation failed. Check server logs for details.'}), 500

    # Generate CSV
    elif output_format == 'csv':
        import csv
        from io import StringIO

        buffer = StringIO()
        writer = csv.writer(buffer)

        # Header info
        writer.writerow(['CISA BOD 22-01 Compliance Report'])
        writer.writerow(['Generated', report['generated_at']])
        writer.writerow(['Status', report['compliance_status']])
        writer.writerow([])

        # Summary
        writer.writerow(['Summary'])
        writer.writerow(['Total KEV Matches', report['summary']['total_kev_matches']])
        writer.writerow(['Remediated', report['summary']['remediated']])
        writer.writerow(['Pending', report['summary']['pending_remediation']])
        writer.writerow(['Compliance %', report['summary']['compliance_percentage']])
        writer.writerow(['Overdue', report['summary']['overdue_count']])
        writer.writerow(['Due Within 7 Days', report['summary']['due_within_7_days']])
        writer.writerow(['Ransomware Exposure', report['summary']['ransomware_exposure']])
        writer.writerow([])

        # Overdue vulnerabilities
        if report['overdue_vulnerabilities']:
            writer.writerow(['Overdue Vulnerabilities'])
            writer.writerow(['CVE ID', 'Product', 'Severity', 'Days Overdue', 'Due Date'])
            for item in report['overdue_vulnerabilities']:
                writer.writerow([
                    item['cve_id'],
                    item['product'],
                    item['severity'] or 'N/A',
                    item['days_overdue'],
                    item['due_date']
                ])
            writer.writerow([])

        # Due soon
        if report['due_soon']:
            writer.writerow(['Due Within 7 Days'])
            writer.writerow(['CVE ID', 'Product', 'Severity', 'Days Remaining', 'Due Date'])
            for item in report['due_soon']:
                writer.writerow([
                    item['cve_id'],
                    item['product'],
                    item['severity'] or 'N/A',
                    item['days_remaining'],
                    item['due_date']
                ])

        # Integrity footer
        writer.writerow([])
        writer.writerow(['Document Integrity'])
        writer.writerow(['Report ID', report.get('report_id', 'N/A')])
        writer.writerow(['SHA-256', report.get('document_integrity', {}).get('content_hash', 'N/A')])
        writer.writerow(['Attestation', report.get('attestation', {}).get('statement', '')])

        buffer.seek(0)
        filename = f"bod_22_01_compliance_{today.strftime('%Y%m%d')}.csv"

        return Response(
            buffer.getvalue(),
            mimetype='text/csv',
            headers={'Content-Disposition': f'attachment; filename={filename}'}
        )

    else:
        return jsonify({'error': 'Invalid format. Use json, csv, or pdf'}), 400


# ============================================================================
# CSV/Excel Export for Vulnerability List
# ============================================================================

@bp.route('/api/reports/export/csv', methods=['GET'])
@login_required
def export_vulnerabilities_csv():
    """
    Export all vulnerability matches as CSV (Excel-compatible).

    Supports the same filters as the vulnerability list API:
        priority: critical, high, medium, low
        acknowledged: true, false
        product_id: Filter by product
        ransomware_only: true/false

    Returns a downloadable CSV file with all vulnerability data.
    """
    import csv
    from io import StringIO
    from app.models import Organization, VulnerabilityMatch, Vulnerability, Product
    from app.filters import get_filtered_vulnerabilities

    try:
        org_id = session.get('organization_id')
        if not org_id:
            default_org = Organization.query.filter_by(name='default').first()
            org_id = default_org.id if default_org else None

        filters = {
            'organization_id': org_id,
            'product_id': request.args.get('product_id', type=int),
            'cve_id': request.args.get('cve_id'),
            'vendor': request.args.get('vendor'),
            'product': request.args.get('product'),
            'ransomware_only': request.args.get('ransomware_only', 'false').lower() == 'true',
            'acknowledged': request.args.get('acknowledged'),
            'priority': request.args.get('priority'),
        }
        filters = {k: v for k, v in filters.items() if v is not None and v != ''}

        matches = get_filtered_vulnerabilities(filters)

        buffer = StringIO()
        # UTF-8 BOM for Excel compatibility
        buffer.write('\ufeff')
        writer = csv.writer(buffer)

        # Header
        writer.writerow([
            'CVE ID',
            'Severity',
            'Priority',
            'CVSS Score',
            'Product',
            'Vendor',
            'Version',
            'Status',
            'Match Confidence',
            'Match Method',
            'Due Date',
            'Days Overdue',
            'Ransomware',
            'EPSS Score',
            'Description',
            'Vendor Fix',
            'Acknowledged At',
            'First Detected',
        ])

        from datetime import date
        today = date.today()

        for m in matches:
            vuln = m.vulnerability
            product = m.product
            priority = m.calculate_effective_priority()

            # Calculate days overdue
            days_overdue = ''
            if vuln.due_date and not m.acknowledged:
                delta = (today - vuln.due_date).days
                if delta > 0:
                    days_overdue = str(delta)

            writer.writerow([
                vuln.cve_id,
                vuln.severity or 'N/A',
                priority or 'N/A',
                str(vuln.cvss_score) if vuln.cvss_score else 'N/A',
                product.product_name,
                product.vendor or '',
                product.version or '',
                'Acknowledged' if m.acknowledged else 'Pending',
                m.match_confidence or 'medium',
                m.match_method or 'keyword',
                vuln.due_date.isoformat() if vuln.due_date else '',
                days_overdue,
                'Yes' if vuln.known_ransomware else 'No',
                str(vuln.epss_score) if hasattr(vuln, 'epss_score') and vuln.epss_score else '',
                (vuln.description or '')[:500],
                m.vendor_fix_confidence or '',
                m.acknowledged_at.isoformat() if m.acknowledged_at else '',
                m.created_at.isoformat() if m.created_at else '',
            ])

        buffer.seek(0)
        filename = f"SentriKat_Vulnerabilities_{datetime.now().strftime('%Y%m%d')}.csv"

        return Response(
            buffer.getvalue(),
            mimetype='text/csv; charset=utf-8',
            headers={'Content-Disposition': f'attachment; filename="{filename}"'}
        )

    except Exception as e:
        logger.exception("Failed to export vulnerabilities as CSV")
        return jsonify({'error': 'An internal error occurred. Check server logs for details.'}), 500


# ============================================================================
# NIS2 Compliance Report
# ============================================================================

@bp.route('/api/reports/compliance/nis2', methods=['GET'])
@login_required
def generate_nis2_compliance_report():
    """
    Generate EU NIS2 Directive compliance report for vulnerability management.

    NIS2 (Directive 2022/2555) Article 21 requires essential and important entities
    to implement vulnerability handling and disclosure policies. This report maps
    SentriKat's vulnerability management data to NIS2 requirements.

    NIS2 Article 21(2) relevant controls:
    (d) Supply chain security
    (e) Vulnerability handling and disclosure
    (g) Basic cyber hygiene practices and cybersecurity training

    Query Parameters:
        format: 'json', 'pdf', or 'csv' (default: json)
        organization_id: Filter by organization (admin only)
    """
    from app.licensing import get_license
    from app.models import Vulnerability, VulnerabilityMatch, Product, Organization, Asset
    from sqlalchemy import func
    from datetime import date, timedelta
    from io import BytesIO

    license_info = get_license()
    if not license_info or not license_info.is_professional():
        return jsonify({
            'error': 'NIS2 Compliance Reports require a Professional license',
            'feature': 'compliance_reports'
        }), 403

    output_format = request.args.get('format', 'json').lower()
    org_id = request.args.get('organization_id', type=int)

    user = User.query.get(session.get('user_id'))
    if not user:
        return jsonify({'error': 'Authentication required'}), 401

    if user.role == 'super_admin' and org_id:
        org_filter = [org_id]
    elif user.role == 'super_admin':
        org_filter = None
    else:
        org_filter = [m.organization_id for m in user.org_memberships.all()]

    today = date.today()

    # Query all matches
    from app.models import product_organizations as po_table
    from sqlalchemy import or_, exists, select

    matches_query = db.session.query(
        VulnerabilityMatch, Vulnerability, Product
    ).join(
        Vulnerability, VulnerabilityMatch.vulnerability_id == Vulnerability.id
    ).join(
        Product, VulnerabilityMatch.product_id == Product.id
    )
    if org_filter:
        # Include products linked via legacy FK or many-to-many org table
        org_link_exists = exists(
            select(po_table.c.product_id).where(
                po_table.c.product_id == Product.id,
                po_table.c.organization_id.in_(org_filter)
            )
        )
        matches_query = matches_query.filter(
            or_(Product.organization_id.in_(org_filter), org_link_exists)
        )

    matches = matches_query.all()

    # Query asset counts
    asset_query = Asset.query.filter(Asset.active == True)
    if org_filter:
        asset_query = asset_query.filter(Asset.organization_id.in_(org_filter))
    total_assets = asset_query.count()

    # Query product counts (include both legacy FK and many-to-many org links)
    product_query = Product.query.filter(Product.active == True)
    if org_filter:
        prod_org_link = exists(
            select(po_table.c.product_id).where(
                po_table.c.product_id == Product.id,
                po_table.c.organization_id.in_(org_filter)
            )
        )
        product_query = product_query.filter(
            or_(Product.organization_id.in_(org_filter), prod_org_link)
        )
    total_products = product_query.count()
    products_with_cpe = product_query.filter(
        Product.cpe_vendor.isnot(None),
        Product.cpe_vendor != '',
        Product.cpe_vendor != '_skip'
    ).count()

    # NIS2 Metrics
    total_matches = len(matches)
    acknowledged = sum(1 for m, v, p in matches if m.acknowledged)
    pending = total_matches - acknowledged

    # Critical/high severity pending
    critical_pending = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'CRITICAL')
    high_pending = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'HIGH')

    # Overdue (past CISA due date)
    overdue = [
        {'cve_id': v.cve_id, 'product': f"{p.vendor} {p.product_name}",
         'severity': v.severity, 'due_date': v.due_date.isoformat(),
         'days_overdue': (today - v.due_date).days, 'ransomware': v.known_ransomware}
        for m, v, p in matches
        if not m.acknowledged and v.due_date and v.due_date < today
    ]

    # Ransomware exposure
    ransomware_pending = sum(1 for m, v, p in matches if not m.acknowledged and v.known_ransomware)

    # Mean time to remediate (acknowledged matches with dates)
    remediation_times = []
    for m, v, p in matches:
        if m.acknowledged and m.acknowledged_at and m.created_at:
            delta = (m.acknowledged_at - m.created_at).days
            if delta >= 0:
                remediation_times.append(delta)
    mttr_days = round(sum(remediation_times) / len(remediation_times), 1) if remediation_times else None

    # CPE coverage (vulnerability identification capability)
    cpe_coverage = round(products_with_cpe / total_products * 100, 1) if total_products > 0 else 0

    # Compliance scoring (mapped to NIS2 Article 21)
    compliance_percent = round(acknowledged / total_matches * 100, 1) if total_matches > 0 else 100.0

    report = {
        'report_type': 'NIS2 Directive - Vulnerability Management Compliance',
        'framework': 'EU Directive 2022/2555 (NIS2)',
        'generated_at': datetime.utcnow().isoformat() + 'Z',
        'report_period': {'as_of_date': today.isoformat()},

        # Article 21(2)(e): Vulnerability handling and disclosure
        'vulnerability_handling': {
            'total_known_exploited_vulnerabilities': total_matches,
            'remediated': acknowledged,
            'pending_remediation': pending,
            'remediation_rate_percent': compliance_percent,
            'critical_severity_pending': critical_pending,
            'high_severity_pending': high_pending,
            'overdue_count': len(overdue),
            'ransomware_exposure': ransomware_pending,
            'mean_time_to_remediate_days': mttr_days,
        },

        # Article 21(2)(d): Supply chain security (asset/product visibility)
        'supply_chain_visibility': {
            'monitored_endpoints': total_assets,
            'tracked_products': total_products,
            'products_with_cpe_identification': products_with_cpe,
            'cpe_coverage_percent': cpe_coverage,
        },

        # Article 21(2)(g): Cyber hygiene assessment
        'cyber_hygiene': {
            'vulnerability_scanning': 'Automated' if total_assets > 0 else 'Not configured',
            'patch_monitoring': 'Active (CISA KEV + vendor advisories)',
            'vendor_backport_detection': 'Enabled (OSV, Red Hat, MSRC, Debian)',
            'false_positive_mitigation': 'Active (3-phase CVE-history-guarded filtering)',
        },

        # Compliance status
        'compliance_status': 'COMPLIANT' if (len(overdue) == 0 and compliance_percent >= 90) else
                             'PARTIALLY COMPLIANT' if compliance_percent >= 50 else
                             'NON-COMPLIANT',

        # Overdue vulnerabilities (top 20)
        'overdue_vulnerabilities': sorted(overdue, key=lambda x: x['days_overdue'], reverse=True)[:20],

        # Recommendations
        'recommendations': [],

        # NIS2 Article mapping
        'nis2_article_mapping': {
            'article_21_2_d': {
                'requirement': 'Supply chain security including security-related aspects of relationships',
                'evidence': f'{total_assets} endpoints monitored, {total_products} products tracked, '
                           f'{cpe_coverage}% CPE identification coverage'
            },
            'article_21_2_e': {
                'requirement': 'Vulnerability handling and disclosure',
                'evidence': f'{compliance_percent}% remediation rate, {total_matches} exploited vulnerabilities tracked, '
                           f'automated CISA KEV + vendor advisory monitoring'
            },
            'article_21_2_g': {
                'requirement': 'Basic cyber hygiene practices',
                'evidence': 'Automated vulnerability scanning, vendor backport detection, '
                           'false positive mitigation via CVE-history-guarded filtering'
            },
        }
    }

    # Recommendations
    if len(overdue) > 0:
        report['recommendations'].append(
            f"URGENT: {len(overdue)} known exploited vulnerabilities are past their remediation deadline. "
            "NIS2 Article 21 requires timely vulnerability handling."
        )
    if ransomware_pending > 0:
        report['recommendations'].append(
            f"HIGH RISK: {ransomware_pending} unpatched vulnerabilities are linked to ransomware campaigns. "
            "NIS2 Article 23 requires incident notification within 24 hours of significant incidents."
        )
    if critical_pending > 0:
        report['recommendations'].append(
            f"CRITICAL: {critical_pending} critical-severity vulnerabilities pending remediation."
        )
    if cpe_coverage < 80:
        report['recommendations'].append(
            f"VISIBILITY GAP: Only {cpe_coverage}% of products have CPE identification. "
            "Assign CPE to remaining products for complete vulnerability coverage."
        )
    if mttr_days and mttr_days > 30:
        report['recommendations'].append(
            f"REMEDIATION SPEED: Mean time to remediate is {mttr_days} days. "
            "NIS2 expects timely vulnerability handling — target <14 days for critical, <30 days for high."
        )

    # Add integrity metadata (signatures, hashes, attestation, audit trail)
    _add_report_integrity(report, generated_by_user=user)

    if output_format == 'json':
        return jsonify(report)

    elif output_format == 'csv':
        import csv
        from io import StringIO

        buffer = StringIO()
        buffer.write('\ufeff')
        writer = csv.writer(buffer)

        writer.writerow(['NIS2 Directive - Vulnerability Management Compliance Report'])
        writer.writerow(['Framework', 'EU Directive 2022/2555 (NIS2)'])
        writer.writerow(['Generated', report['generated_at']])
        writer.writerow(['Status', report['compliance_status']])
        writer.writerow([])

        writer.writerow(['Article 21(2)(e) - Vulnerability Handling'])
        for key, value in report['vulnerability_handling'].items():
            writer.writerow([key.replace('_', ' ').title(), value])
        writer.writerow([])

        writer.writerow(['Article 21(2)(d) - Supply Chain Visibility'])
        for key, value in report['supply_chain_visibility'].items():
            writer.writerow([key.replace('_', ' ').title(), value])
        writer.writerow([])

        if overdue:
            writer.writerow(['Overdue Vulnerabilities'])
            writer.writerow(['CVE ID', 'Product', 'Severity', 'Days Overdue', 'Ransomware'])
            for item in sorted(overdue, key=lambda x: x['days_overdue'], reverse=True)[:20]:
                writer.writerow([item['cve_id'], item['product'], item['severity'],
                                item['days_overdue'], 'Yes' if item.get('ransomware') else 'No'])
            writer.writerow([])

        writer.writerow(['Recommendations'])
        for rec in report['recommendations']:
            writer.writerow([rec])

        # Integrity footer
        writer.writerow([])
        writer.writerow(['Document Integrity'])
        writer.writerow(['Report ID', report.get('report_id', 'N/A')])
        writer.writerow(['SHA-256', report.get('document_integrity', {}).get('content_hash', 'N/A')])
        writer.writerow(['Attestation', report.get('attestation', {}).get('statement', '')])

        buffer.seek(0)
        filename = f"nis2_compliance_{today.strftime('%Y%m%d')}.csv"
        return Response(
            buffer.getvalue(),
            mimetype='text/csv; charset=utf-8',
            headers={'Content-Disposition': f'attachment; filename="{filename}"'}
        )

    elif output_format == 'pdf':
        try:
            from reportlab.lib import colors
            from reportlab.lib.pagesizes import letter
            from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch

            buffer = BytesIO()
            doc = SimpleDocTemplate(buffer, pagesize=letter)
            styles = getSampleStyleSheet()
            story = []

            # Title
            title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=18, spaceAfter=20)
            story.append(Paragraph("NIS2 Vulnerability Management Compliance", title_style))
            story.append(Paragraph("EU Directive 2022/2555 - Article 21 Assessment", styles['Heading3']))
            story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M UTC')}", styles['Normal']))
            story.append(Spacer(1, 20))

            # Status
            status_color = colors.green if 'COMPLIANT' == report['compliance_status'] else \
                          colors.orange if 'PARTIALLY' in report['compliance_status'] else colors.red
            status_style = ParagraphStyle('Status', parent=styles['Heading2'], textColor=status_color)
            story.append(Paragraph(f"Status: {report['compliance_status']}", status_style))
            story.append(Spacer(1, 20))

            # Summary table
            vuln = report['vulnerability_handling']
            summary_data = [
                ['Metric', 'Value'],
                ['Known Exploited Vulnerabilities', str(vuln['total_known_exploited_vulnerabilities'])],
                ['Remediated', str(vuln['remediated'])],
                ['Pending Remediation', str(vuln['pending_remediation'])],
                ['Remediation Rate', f"{vuln['remediation_rate_percent']}%"],
                ['Critical Pending', str(vuln['critical_severity_pending'])],
                ['Overdue', str(vuln['overdue_count'])],
                ['Ransomware Exposure', str(vuln['ransomware_exposure'])],
                ['Mean Time to Remediate', f"{vuln['mean_time_to_remediate_days']} days" if vuln['mean_time_to_remediate_days'] else 'N/A'],
            ]
            t = Table(summary_data, colWidths=[3*inch, 2*inch])
            t.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#003399')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ]))
            story.append(t)
            story.append(Spacer(1, 20))

            # Supply chain visibility
            story.append(Paragraph("Supply Chain Visibility (Article 21(2)(d))", styles['Heading2']))
            sc = report['supply_chain_visibility']
            sc_data = [
                ['Metric', 'Value'],
                ['Monitored Endpoints', str(sc['monitored_endpoints'])],
                ['Tracked Products', str(sc['tracked_products'])],
                ['CPE Identification Coverage', f"{sc['cpe_coverage_percent']}%"],
            ]
            t2 = Table(sc_data, colWidths=[3*inch, 2*inch])
            t2.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ]))
            story.append(t2)
            story.append(Spacer(1, 20))

            # Recommendations
            if report['recommendations']:
                story.append(Paragraph("Recommendations", styles['Heading2']))
                for rec in report['recommendations']:
                    story.append(Paragraph(f"&bull; {rec}", styles['Normal']))
                story.append(Spacer(1, 10))

            # Attestation & Integrity footer
            story.append(Spacer(1, 30))
            footer_style = ParagraphStyle('Footer', parent=styles['Normal'], fontSize=7, textColor=colors.grey)
            story.append(Paragraph(f"Report ID: {report.get('report_id', 'N/A')}", footer_style))
            story.append(Paragraph(f"SHA-256: {report.get('document_integrity', {}).get('content_hash', 'N/A')}", footer_style))
            story.append(Paragraph(report.get('attestation', {}).get('statement', ''), footer_style))

            doc.build(story)
            buffer.seek(0)

            filename = f"nis2_compliance_{today.strftime('%Y%m%d')}.pdf"
            return send_file(buffer, mimetype='application/pdf', as_attachment=True, download_name=filename)

        except ImportError:
            return jsonify({'error': 'PDF generation requires reportlab library'}), 500
        except Exception as e:
            logger.exception("Error generating NIS2 compliance PDF")
            return jsonify({'error': 'PDF generation failed. Check server logs for details.'}), 500

    else:
        return jsonify({'error': 'Invalid format. Use json, csv, or pdf'}), 400


# ============================================================================
# Executive Summary One-Pager
# ============================================================================

@bp.route('/api/reports/executive-summary', methods=['GET'])
@login_required
def generate_executive_summary():
    """
    Generate a one-page executive summary PDF for board/management reporting.

    This is the "executive" report type that the UI promises.
    Contains: risk score, vulnerability trend, top priorities, KPIs.

    Query Parameters:
        format: 'json' or 'pdf' (default: pdf)
        organization_id: Filter by organization (admin only)
    """
    from app.licensing import get_license
    from app.models import Vulnerability, VulnerabilityMatch, Product, Organization, Asset, VulnerabilitySnapshot
    from datetime import date, timedelta
    from io import BytesIO

    license_info = get_license()
    if not license_info or not license_info.is_professional():
        return jsonify({
            'error': 'Executive Summary reports require a Professional license',
            'feature': 'executive_reports'
        }), 403

    output_format = request.args.get('format', 'pdf').lower()
    org_id = request.args.get('organization_id', type=int)

    user = User.query.get(session.get('user_id'))
    if not user:
        return jsonify({'error': 'Authentication required'}), 401

    if user.role == 'super_admin' and org_id:
        org_filter = [org_id]
    elif user.role == 'super_admin':
        org_filter = None
    else:
        org_filter = [m.organization_id for m in user.org_memberships.all()]

    today = date.today()

    # Get organization name
    org_name = 'All Organizations'
    if org_filter and len(org_filter) == 1:
        org = Organization.query.get(org_filter[0])
        if org:
            org_name = org.name

    # Query matches
    matches_query = db.session.query(
        VulnerabilityMatch, Vulnerability, Product
    ).join(
        Vulnerability, VulnerabilityMatch.vulnerability_id == Vulnerability.id
    ).join(
        Product, VulnerabilityMatch.product_id == Product.id
    )
    if org_filter:
        matches_query = matches_query.filter(Product.organization_id.in_(org_filter))
    matches = matches_query.all()

    # Asset count
    asset_query = Asset.query.filter(Asset.active == True)
    if org_filter:
        asset_query = asset_query.filter(Asset.organization_id.in_(org_filter))
    total_assets = asset_query.count()

    # KPIs
    total = len(matches)
    acknowledged = sum(1 for m, v, p in matches if m.acknowledged)
    pending = total - acknowledged
    critical = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'CRITICAL')
    high = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'HIGH')
    medium = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'MEDIUM')
    low = sum(1 for m, v, p in matches if not m.acknowledged and v.severity == 'LOW')
    ransomware = sum(1 for m, v, p in matches if not m.acknowledged and v.known_ransomware)
    overdue = sum(1 for m, v, p in matches if not m.acknowledged and v.due_date and v.due_date < today)

    # MTTR
    remediation_times = []
    for m, v, p in matches:
        if m.acknowledged and m.acknowledged_at and m.created_at:
            delta = (m.acknowledged_at - m.created_at).days
            if delta >= 0:
                remediation_times.append(delta)
    mttr = round(sum(remediation_times) / len(remediation_times), 1) if remediation_times else None

    # Risk score (0-100): higher = worse
    risk_score = min(100, round(
        (critical * 25 + high * 10 + medium * 3 + low * 1 + ransomware * 15 + overdue * 20) /
        max(total_assets, 1) * 10
    )) if pending > 0 else 0

    # Top 5 most urgent vulnerabilities
    urgent = []
    for m, v, p in matches:
        if not m.acknowledged:
            score = 0
            if v.severity == 'CRITICAL':
                score += 40
            elif v.severity == 'HIGH':
                score += 25
            if v.known_ransomware:
                score += 30
            if v.due_date and v.due_date < today:
                score += 20 + min((today - v.due_date).days, 30)
            urgent.append({
                'cve_id': v.cve_id,
                'product': f"{p.vendor} {p.product_name}",
                'severity': v.severity,
                'ransomware': v.known_ransomware,
                'score': score
            })
    urgent.sort(key=lambda x: x['score'], reverse=True)
    top_urgent = urgent[:5]

    report_data = {
        'report_type': 'Executive Summary',
        'organization': org_name,
        'generated_at': datetime.utcnow().isoformat() + 'Z',
        'as_of_date': today.isoformat(),
        'risk_score': risk_score,
        'kpis': {
            'monitored_endpoints': total_assets,
            'total_vulnerability_matches': total,
            'remediated': acknowledged,
            'pending_action': pending,
            'remediation_rate_percent': round(acknowledged / total * 100, 1) if total > 0 else 100.0,
            'mean_time_to_remediate_days': mttr,
        },
        'severity_breakdown': {
            'critical': critical,
            'high': high,
            'medium': medium,
            'low': low,
        },
        'risk_indicators': {
            'ransomware_exposure': ransomware,
            'overdue_remediation': overdue,
        },
        'top_priorities': top_urgent,
    }

    if output_format == 'json':
        return jsonify(report_data)

    # Generate one-page PDF
    try:
        from reportlab.lib import colors
        from reportlab.lib.pagesizes import letter
        from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
        from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
        from reportlab.lib.units import inch

        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter,
                                topMargin=0.5*inch, bottomMargin=0.5*inch,
                                leftMargin=0.75*inch, rightMargin=0.75*inch)
        styles = getSampleStyleSheet()
        story = []

        # Header
        title_style = ParagraphStyle('Title', parent=styles['Heading1'], fontSize=20, spaceAfter=5)
        story.append(Paragraph("Security Posture — Executive Summary", title_style))
        story.append(Paragraph(f"{org_name} | {today.strftime('%B %d, %Y')}", styles['Normal']))
        story.append(Spacer(1, 15))

        # Risk Score with color
        risk_color = colors.green if risk_score < 30 else colors.orange if risk_score < 70 else colors.red
        risk_label = 'LOW' if risk_score < 30 else 'MODERATE' if risk_score < 70 else 'HIGH'
        risk_style = ParagraphStyle('Risk', parent=styles['Heading1'], fontSize=28,
                                    textColor=risk_color, alignment=1)
        story.append(Paragraph(f"Risk Score: {risk_score}/100 ({risk_label})", risk_style))
        story.append(Spacer(1, 15))

        # KPI row
        kpi_data = [
            ['Endpoints', 'Vulnerabilities', 'Remediated', 'Pending', 'Remediation Rate', 'MTTR'],
            [str(total_assets), str(total), str(acknowledged), str(pending),
             f"{report_data['kpis']['remediation_rate_percent']}%",
             f"{mttr}d" if mttr else 'N/A']
        ]
        kpi_table = Table(kpi_data, colWidths=[1.1*inch]*6)
        kpi_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2C3E50')),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('GRID', (0, 0), (-1, -1), 1, colors.grey),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('FONTSIZE', (0, 1), (-1, 1), 14),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
        ]))
        story.append(kpi_table)
        story.append(Spacer(1, 15))

        # Severity breakdown + risk indicators side by side
        sev_data = [
            ['Severity', 'Pending'],
            ['CRITICAL', str(critical)],
            ['HIGH', str(high)],
            ['MEDIUM', str(medium)],
            ['LOW', str(low)],
        ]
        sev_table = Table(sev_data, colWidths=[1.5*inch, 1*inch])
        sev_colors = [colors.darkred, colors.orangered, colors.orange, colors.green]
        sev_style = [
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ]
        for i, c in enumerate(sev_colors):
            sev_style.append(('TEXTCOLOR', (0, i+1), (0, i+1), c))
            sev_style.append(('FONTNAME', (0, i+1), (0, i+1), 'Helvetica-Bold'))
        sev_table.setStyle(TableStyle(sev_style))

        risk_data = [
            ['Risk Indicator', 'Count'],
            ['Ransomware Exposure', str(ransomware)],
            ['Overdue Remediation', str(overdue)],
        ]
        risk_table = Table(risk_data, colWidths=[2*inch, 1*inch])
        risk_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
            ('TEXTCOLOR', (1, 1), (1, 2), colors.red if (ransomware > 0 or overdue > 0) else colors.green),
        ]))

        side_by_side = Table([[sev_table, risk_table]], colWidths=[2.8*inch, 3.5*inch])
        story.append(side_by_side)
        story.append(Spacer(1, 15))

        # Top priorities
        if top_urgent:
            story.append(Paragraph("Top Priorities", styles['Heading2']))
            prio_data = [['CVE', 'Product', 'Severity', 'Ransomware']]
            for item in top_urgent:
                prio_data.append([
                    item['cve_id'],
                    item['product'][:35],
                    item['severity'] or 'N/A',
                    'Yes' if item['ransomware'] else 'No'
                ])
            prio_table = Table(prio_data, colWidths=[1.5*inch, 2.5*inch, 1*inch, 1*inch])
            prio_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#2C3E50')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('GRID', (0, 0), (-1, -1), 1, colors.black),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, -1), 8),
            ]))
            story.append(prio_table)

        # Footer
        story.append(Spacer(1, 20))
        footer_style = ParagraphStyle('Footer', parent=styles['Normal'], fontSize=7, textColor=colors.grey)
        story.append(Paragraph(
            f"Generated by SentriKat | {datetime.now().strftime('%Y-%m-%d %H:%M UTC')} | "
            "Data sources: CISA KEV, NVD, OSV.dev, Red Hat, MSRC, Debian",
            footer_style
        ))

        doc.build(story)
        buffer.seek(0)

        filename = f"SentriKat_Executive_Summary_{today.strftime('%Y%m%d')}.pdf"
        return send_file(buffer, mimetype='application/pdf', as_attachment=True, download_name=filename)

    except ImportError:
        return jsonify({'error': 'PDF generation requires reportlab library'}), 500
    except Exception as e:
        logger.exception("Error generating executive summary PDF")
        return jsonify({'error': f'PDF generation failed: {str(e)}'}), 500


# ============================================================================
# Syslog / CEF Forwarding
# ============================================================================

@bp.route('/api/settings/syslog', methods=['GET'])
@login_required
def get_syslog_settings():
    """Get current syslog forwarding configuration."""
    from app.models import SystemSettings

    settings = {}
    for key in ['syslog_enabled', 'syslog_host', 'syslog_port', 'syslog_protocol',
                'syslog_format', 'syslog_facility']:
        setting = SystemSettings.query.filter_by(key=key).first()
        settings[key] = setting.value if setting else None

    return jsonify({
        'enabled': settings.get('syslog_enabled', 'false') == 'true',
        'host': settings.get('syslog_host', ''),
        'port': int(settings.get('syslog_port', '514') or '514'),
        'protocol': settings.get('syslog_protocol', 'udp'),
        'format': settings.get('syslog_format', 'cef'),
        'facility': settings.get('syslog_facility', 'local0'),
    })


@bp.route('/api/settings/syslog', methods=['POST'])
@login_required
def update_syslog_settings():
    """Update syslog forwarding configuration."""
    from app.models import SystemSettings

    data = request.get_json()
    if not data:
        return jsonify({'error': 'No data provided'}), 400

    # Validate
    protocol = data.get('protocol', 'udp')
    if protocol not in ('udp', 'tcp'):
        return jsonify({'error': 'Protocol must be udp or tcp'}), 400

    fmt = data.get('format', 'cef')
    if fmt not in ('cef', 'json', 'rfc5424'):
        return jsonify({'error': 'Format must be cef, json, or rfc5424'}), 400

    port = int(data.get('port', 514))
    if port < 1 or port > 65535:
        return jsonify({'error': 'Port must be 1-65535'}), 400

    # Save settings
    settings_map = {
        'syslog_enabled': str(data.get('enabled', False)).lower(),
        'syslog_host': data.get('host', ''),
        'syslog_port': str(port),
        'syslog_protocol': protocol,
        'syslog_format': fmt,
        'syslog_facility': data.get('facility', 'local0'),
    }

    for key, value in settings_map.items():
        setting = SystemSettings.query.filter_by(key=key).first()
        if setting:
            setting.value = value
        else:
            setting = SystemSettings(key=key, value=value)
            db.session.add(setting)

    db.session.commit()

    return jsonify({'success': True, 'message': 'Syslog settings updated'})


@bp.route('/api/settings/syslog/test', methods=['POST'])
@login_required
def test_syslog():
    """Send a test message to the configured syslog server."""
    try:
        result = send_syslog_event(
            event_type='test',
            cve_id='CVE-0000-0000',
            severity='MEDIUM',
            product='SentriKat Test',
            message='Test syslog message from SentriKat'
        )
        if result:
            return jsonify({'success': True, 'message': 'Test message sent'})
        else:
            return jsonify({'success': False, 'message': 'Syslog is not enabled or misconfigured'}), 400
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)}), 500


def send_syslog_event(event_type, cve_id, severity, product, message, **kwargs):
    """
    Send a single event to the configured syslog server.

    Supports formats:
    - CEF (ArcSight Common Event Format) — standard for SIEM ingestion
    - JSON — structured JSON for ELK/Splunk HEC
    - RFC 5424 — standard syslog format

    Args:
        event_type: 'new_vulnerability', 'acknowledged', 'overdue', 'test'
        cve_id: CVE identifier
        severity: CRITICAL, HIGH, MEDIUM, LOW
        product: Affected product name
        message: Human-readable description
        **kwargs: Additional fields (vendor, due_date, ransomware, etc.)

    Returns:
        True if sent successfully, False if syslog not configured
    """
    import socket
    from app.models import SystemSettings

    # Check if enabled
    enabled_setting = SystemSettings.query.filter_by(key='syslog_enabled').first()
    if not enabled_setting or enabled_setting.value != 'true':
        return False

    host_setting = SystemSettings.query.filter_by(key='syslog_host').first()
    port_setting = SystemSettings.query.filter_by(key='syslog_port').first()
    protocol_setting = SystemSettings.query.filter_by(key='syslog_protocol').first()
    format_setting = SystemSettings.query.filter_by(key='syslog_format').first()
    facility_setting = SystemSettings.query.filter_by(key='syslog_facility').first()

    host = host_setting.value if host_setting else ''
    port = int(port_setting.value) if port_setting else 514
    protocol = protocol_setting.value if protocol_setting else 'udp'
    fmt = format_setting.value if format_setting else 'cef'
    facility = facility_setting.value if facility_setting else 'local0'

    if not host:
        return False

    # Map severity to syslog priority
    severity_map = {'CRITICAL': 2, 'HIGH': 3, 'MEDIUM': 4, 'LOW': 5}
    facility_map = {
        'local0': 16, 'local1': 17, 'local2': 18, 'local3': 19,
        'local4': 20, 'local5': 21, 'local6': 22, 'local7': 23,
    }
    syslog_severity = severity_map.get(severity, 5)
    syslog_facility = facility_map.get(facility, 16)
    priority = syslog_facility * 8 + syslog_severity

    timestamp = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')

    if fmt == 'cef':
        # CEF format: CEF:0|Vendor|Product|Version|EventID|Name|Severity|Extensions
        cef_severity = {'CRITICAL': 10, 'HIGH': 8, 'MEDIUM': 5, 'LOW': 3}.get(severity, 1)
        extensions = f"cveId={cve_id} product={product} msg={message}"
        if kwargs.get('vendor'):
            extensions += f" vendor={kwargs['vendor']}"
        if kwargs.get('due_date'):
            extensions += f" dueDate={kwargs['due_date']}"
        if kwargs.get('ransomware'):
            extensions += " ransomware=true"
        payload = (
            f"<{priority}>{timestamp} SentriKat "
            f"CEF:0|SentriKat|VulnerabilityManagement|1.0|{event_type}|"
            f"{cve_id} {severity}|{cef_severity}|{extensions}"
        )
    elif fmt == 'json':
        import json
        event = {
            'timestamp': timestamp,
            'source': 'SentriKat',
            'event_type': event_type,
            'cve_id': cve_id,
            'severity': severity,
            'product': product,
            'message': message,
        }
        event.update(kwargs)
        payload = f"<{priority}>{timestamp} SentriKat {json.dumps(event)}"
    else:  # rfc5424
        payload = (
            f"<{priority}>1 {timestamp} SentriKat VulnerabilityManagement - "
            f"{event_type} - {cve_id} {severity} {product}: {message}"
        )

    try:
        encoded = payload.encode('utf-8')
        if protocol == 'tcp':
            sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            sock.settimeout(5)
            sock.connect((host, port))
            sock.sendall(encoded + b'\n')
            sock.close()
        else:
            sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            sock.settimeout(5)
            sock.sendto(encoded, (host, port))
            sock.close()
        return True
    except Exception as e:
        logger.error(f"Syslog send failed: {e}")
        return False
